{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dde2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "def decode(l):\n",
    "    return ''.join([itos[i] for i in l])\n",
    "\n",
    "\n",
    "# NLTK function to generate ngrams\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68ec057",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron = load_dataset(\"snoop2head/enron_aeslc_emails\", num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9c60e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_enron_doc(text_list):\n",
    "    processed_list = [None] * len(text_list)\n",
    "\n",
    "    for i in range(0, len(text_list)):\n",
    "        doc = text_list[i]\n",
    "        #remove title \n",
    "        body = doc.partition(\"Body:\")[2]\n",
    "        #remove foreign characters, numbers, punctuation, line breaks, and go to lowercase\n",
    "        processed_list[i] = re.sub(r'[^a-zA-z ]', ' ', body).translate(\n",
    "            str.maketrans(\"\",\"\", string.punctuation)).replace(\n",
    "            \"\\n\", \" \").lower()\n",
    "    return processed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f467bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_branching_factor(text, prev_word_dic={}, find_count=False):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    word_dic = prev_word_dic\n",
    "    for i,word in enumerate(words):\n",
    "        if len(words) == i+1:\n",
    "            continue\n",
    "        if word_dic.get(word) == None:\n",
    "            word_dic[word] = set([words[i+1]])\n",
    "        else:\n",
    "            w_set = word_dic[word]\n",
    "            w_set.add(words[i+1])\n",
    "    count = 0\n",
    "    if find_count: \n",
    "        for k,v in word_dic.items():\n",
    "            count += len(v)\n",
    "        return count/len(word_dic)\n",
    "    return word_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4155e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_processed_doc = process_enron_doc(enron['train']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d859e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  randy   can you send me a schedule of the salary and level of everyone in the  scheduling group   plus your thoughts on any changes that need to be made     patti s for example  phillip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_processed_doc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "679ecbba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m         final_dic \u001b[38;5;241m=\u001b[39m avg_branching_factor(enron_processed_doc[i], prev_word_dic \u001b[38;5;241m=\u001b[39m prev_dic)\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m final_dic\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 9\u001b[0m             count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(v)\n\u001b[1;32m     10\u001b[0m         result_enron \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(final_dic)\n\u001b[1;32m     11\u001b[0m result_enron\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(enron_processed_doc)): \n",
    "    if i == 0:\n",
    "        prev_dic = avg_branching_factor(enron_processed_doc[i])\n",
    "    elif i < len(enron_processed_doc) - 1:\n",
    "        prev_dic = avg_branching_factor(enron_processed_doc[i], prev_word_dic = prev_dic)\n",
    "    else:\n",
    "        final_dic = avg_branching_factor(enron_processed_doc[i], prev_word_dic = prev_dic)\n",
    "        for k,v in final_dic.items():\n",
    "            count += len(v)\n",
    "        result_enron = count/len(final_dic)\n",
    "result_enron\n",
    "#final dic is getting saved too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14e84ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.67294048616932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for k,v in final_dic.items():\n",
    "        count += len(v)\n",
    "result_enron = count/len(final_dic)\n",
    "result_enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c1c1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dic.items()) #about 700 smaller than the vocab size "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
